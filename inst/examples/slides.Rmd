---
title: "Untitled"
output: ioslides_presentation
---

### Data processing is a major effort and should not be underestimated

We have built custom tools to automate all analyses from raw data to final summary documents (these slides, for instance).

\begin{columns}
\begin{column}{0.5\textwidth}
     \includegraphics[width=1\textwidth]{parsing.png}
\end{column}
\begin{column}{0.5\textwidth}  %%<--- here
    \begin{center}
     \includegraphics[width=1\textwidth]{iceberg.png}
     \end{center}
\end{column}
\end{columns}


---

![](ecosystemflowchart.png)


---

### Data: bibliographic catalogues 1640-1828  


**Fennica** Finnish National bibliography

- 900,000+ books and monographies (printed and electronic; 1488-)
- 70,000+ continuous publications (journals or series; 1771-)
- Series, maps, audiovisual, electronic material
- `r nrow(subset(df0, catalog == "Fennica" & publication_year >= 1640 & publication_year < 1828))` documents 1640-1828

**Kungliga**  Swedish National bibliography

- `r nrow(subset(df0, catalog == "Kungliga" & publication_year >= 1640 & publication_year < 1828))` documents 1640-1828
- Altogether > 18 million entries

```{r, message=FALSE, warning=FALSE, fig.width=10, fig.height=3, echo=FALSE}
library(dplyr)
library(ggplot2)
theme_set(theme_bw(20))
df <- df0 %>% filter(publication_year >=1640 & publication_year <=1828) %>% group_by(catalog, publication_decade) %>% tally()
p <- ggplot(df, aes(x = publication_decade, y = n, color = catalog)) + 
       geom_point() + 
       geom_line() + 
       ylab("Documents (n)") + xlab("Publication year") +
       scale_color_manual(values = c("blue", "darkgreen"))
print(p)
```

---

## Analyse & Visualize

**Fast time line analysis**

```{r, fig.width=15, fig.height=5, message=FALSE, warning=FALSE}
library(bibliographica)
titlecount_timeline(subset(df0, catalog == "Fennica"), 
          "publisher", nmin = 500, mode = "n")$plot
```

---


### Comparing publishing activity in Stockholm and Turku

```{r publishingactivitycomparisons, echo=FALSE, message=FALSE, cache=TRUE, fig.width=10, fig.height=9, fig.show="hold", out.width="160px"}
v <- seq(1500, 1800, 100)
selected.places = c("Turku", "Stockholm")
df2 <- df0 %>% group_by(publication_decade, publication_place, catalog) %>%
               summarise(n = n()) %>%
	       filter(publication_place %in% selected.places) 
df2$catalog = factor(df2$catalog, levels = rev(c("Fennica", "Kungliga")))
df2$publication_place = droplevels(factor(df2$publication_place))
df3 = as.data.frame(spread(df2, publication_decade, n, fill = 0))
df2 = melt(df3)
colnames(df2) = c("publication_place", "catalog", "publication_decade", "n")
df2$publication_decade = as.numeric(as.character(df2$publication_decade))
df2$n = as.numeric(as.character(df2$n))
for (catal in unique(df2$catalog)) {
  p <- ggplot(subset(df2, catalog == catal), aes(x = publication_decade, y = n)) +
     geom_line(aes(linetype = publication_place)) +
     geom_point(aes(shape = publication_place), size = 3) +
     ylab("Title count (n)") + xlab("Publication year") +  
     ggtitle(catal) +
     scale_x_continuous(breaks = v, labels = v) + 
     theme(axis.text.x = element_text(angle = 0))
  print(p)

}
```

---

### Language comparison between catalogues (percentage)

```{r languageperc, echo=FALSE, message=FALSE, warning=FALSE, fig.width=15, fig.height=10}
pics <- list()
for (catalogue in c("Fennica", "Kungliga")) {

  if (catalogue == "Fennica") {
    df <- df.full # full time span
  } else if (catalogue == "Kungliga") {
    df <- df.full # full time span
  }
  langs <- c("Finnish", "Swedish", "Latin", "German", "Russian", "French", "Other")
  df <- df %>% filter(catalog == catalogue)%>%
        filter(publication_year >= 1600 & publication_year <= 1900)

library(dplyr)
library(tidyr)
library(magrittr)
library(reshape2)
  
lang <- paste("language.", langs, sep = "")
otherlang <- setdiff(names(df)[grep("lang.", names(df))], lang)
df$language.Other <- rowSums(df[, otherlang] == TRUE, na.rm = T) > 0

dfl <- NULL
for (lan in lang) {

  # Classify a document to the specifed language
  # If document is assigned with languages, each case is considered
  # so one doc may have multiple entries corresponding to different languages
  # mean(rowSums(df[, lang]) == 1) # 93% Fennica docs have just 1 language
  # Combine data frames for specified languages
  dflsub <- filter(df, df[[lan]])
  if (nrow(dflsub)>0) {
    dflsub$language <- gsub("language.", "", lan)
    dfl <- bind_rows(dfl, dflsub)
  }
}

df <- dfl %>% group_by(publication_decade, language) %>%
     	     summarise(n = n())

# Calculate percentages
dff <- spread(df, language, n, fill = 0)
dff[, -1] <- 100 * t(apply(dff[, -1], 1, function (x) {x/sum(x)}))
dff <- melt(dff, "publication_decade");
colnames(dff) <- c("publication_decade", "language", "f")

theme_set(theme_bw(20))
p <- ggplot(dff, aes(x = publication_decade, y = f)) +
     geom_bar(position = "stack", stat = "identity", aes(fill = language)) + 
     xlab("Publication year") +
     ylab("Title count frequency (%)") +
     #ggtitle(paste("Languages (", catalogue, ")", sep = "")) +
     ggtitle(catalogue) +
     guides(fill = guide_legend(reverse = TRUE, title = "")) +
     scale_fill_brewer(palette="Paired")
pics[[catalogue]] <- p
library(dplyr)
library(magrittr)
}
library(gridExtra)
grid.arrange(pics[[1]], pics[[2]], nrow = 2)
```
