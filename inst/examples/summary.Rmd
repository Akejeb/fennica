---
title: "Preprocessing summary"
author: "Leo Lahti and Niko Ilom√§ki"
date: "March 2, 2016"
output: markdown_document
---

# Fennica summary

## Annotated documents

Fraction of documents with entries for each annotation field. For a full list of summaries for field contents, see [here](https://github.com/rOpenGov/fennica/tree/master/inst/examples/output.tables).

```{r missing, echo=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.width=10, fig.height=15}
library(stringr)
library(dplyr)
library(reshape2)
library(ggplot2)
ntop <- 20

# Read the preprocessed data
df <- readRDS("df.Rds")
df.orig <- readRDS("df.orig.Rds")
```

Conversions from the original to preprocessed fields:

```{r summary-conversions, echo=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.width=10, fig.height=15}
field.conversions <- cbind(harmonize_field_names(), preprocessed = unname(sapply(conversions, function (x) {paste(x, collapse = ";")})[as.character(harmonize_field_names()$name)]))
names(field.conversions) <- c("marc_clearname", "marc_field", "preprocessed_fields")
field.conversions <- field.conversions[, c(2, 1, 3)]
kable(field.conversions)
```


Percentage of non-NA entries among all documents in the preprocessed data (note that in some cases a significant fraction of this information is missing already in the raw data)

```{r missingb, echo=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.width=10, fig.height=15}
# Need to use this trick to have NAs for all data types
missing <- 100*apply(df, 2, function (x) {mean(is.na(gsub("^NA$", NA, as.character(x))))})
df2 <- data.frame(list(missing = missing, field = names(missing)))
df2$field <- factor(df2$field, levels = df2$field[rev(order(df2$missing))])

theme_set(theme_bw(15))
p <- ggplot(df2, aes(x = field, y = 100 - missing))
p <- p + geom_bar(stat = "identity")
p <- p + coord_flip()
p <- p + ylab("")
p <- p + xlab("")
p <- p + ggtitle("Documents with data (%)")
print(p)
```


Fields of special interest: real success percentage (proportion of successful conversions compared to non-NA entries in the original data):

```{r missing2, echo=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.width=10, fig.height=15}
dfs <- df %>% select(author, publication_place, country, publication_year, publication_year_from, publication_year_till, corporate, area, pagecount, gatherings, width, height, paper.consumption.km2, publisher, self_published)
success <- as.data.frame(t(apply(dfs, 2, function (x) {sum(!is.na(gsub("^NA$", NA, as.character(x))))})))
original.nonNA <- as.data.frame(t(apply(select(df.orig, publication_place, publication_time, corporate, physical_extent, physical_dimension, publisher, author_name), 2, function (x) {sum(!is.na(gsub("^NA$", NA, as.character(x))))})))

# Compare the number of non-NA entries in preprocessed data to number
# of non-NA entries in the original data:
real.success <- c()
real.success[["publication_place"]] <- success$publication_place/original.nonNA$publication_place
real.success[["country"]] <- success$country/original.nonNA$publication_place
real.success[["publication_year"]] <- success$publication_year/original.nonNA$publication_time
real.success[["publication_year_from"]] <- success$publication_year_from/original.nonNA$publication_time
real.success[["publication_year_till"]] <- success$publication_year_till/original.nonNA$publication_time
real.success[["corporate"]] <- success$corporate/original.nonNA$corporate
real.success[["publisher"]] <- success$publisher/original.nonNA$publisher
real.success[["self_published"]] <- success$self_published/original.nonNA$publisher
real.success[["pagecount"]] <- success$pagecount/original.nonNA$physical_extent
real.success[["area"]] <- success$area/original.nonNA$physical_dimension
real.success[["gatherings"]] <- success$gatherings/original.nonNA$physical_dimension
real.success[["author"]] <- success$author/original.nonNA$author
real.success[["paper"]] <- success$paper.consumption.km2/sum(rowMeans(!is.na(df.orig[, c("physical_extent", "physical_dimension")])) == 1)
par(mar = c(3, 8, 2, 1)); barplot(100*sort(real.success), horiz = T, main = "Real success rate (selected fields)", las = 1, xlim = c(0, 100), xlab = "Success rate (%)")
```

## Pagecounts

[Discarded page count data](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/pagecount_discarded.csv)

[Successfully converted page counts](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/pagecount_conversion.csv)

Compare gatherings and cm2 sizes as a quality check. This includes all data; the area has been estimated from the gatherings when dimension information was not available.

```{r summarysizecomp, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=7}
dfs <- df %>% filter(!is.na(area) & !is.na(gatherings))
dfs <- dfs[, c("gatherings", "area")]
dfm <- melt(table(dfs))
names(dfm) <- c("gatherings", "area", "documents")
dfm$gatherings <- order_gatherings(dfm$gatherings)
p <- ggplot(dfm, aes(x = gatherings, y = area)) 
p <- p + scale_y_continuous(trans = "log2")
p <- p + geom_point(aes(size = documents))
p <- p + scale_size(trans="log10")
p <- p + ggtitle("Document size distribution: gatherings vs. cm2")
p <- p + xlab("Size (gatherings)")
p <- p + ylab("Size (cm2)")
p <- p + coord_flip()
print(p)
```

Compare gatherings and page counts. 

```{r summarypagecomp, echo=FALSE, message=FALSE, warning=FALSE, fig.width=15, fig.height=7}
dfs <- select(df, pagecount, gatherings) 
dfs$pagecount <- as.numeric(gsub(" pages", "", dfs$pagecount))
dfs <- dfs %>% filter(!is.na(pagecount) & !is.na(gatherings))
dfg <- group_by(dfs, pagecount, gatherings) %>% tally()
names(dfg) <- c("pages", "gatherings", "documents")
dfg$gatherings <- order_gatherings(dfg$gatherings)
ylims <- range(dfg$pages)
p <- ggplot(dfg, aes(x = gatherings, y = pages)) 
n <- nchar(max(na.omit(table(dfg$pages))))
ylim <- ylim(ylims)
p <- p + scale_y_log10(breaks=10^(0:n))
p <- p + geom_point(aes(size = documents))
p <- p + scale_size(trans="log10")
p <- p + xlab("Size (gatherings)")
p <- p + ylab("Pages (original and estimated)")
p <- p + coord_flip()
print(p)
```

## Publication time

[Successfully converted publication times](output.tables/publication-time-accepted.csv)

[Discarded publication times](output.tables/publication-time-discarded.csv)

```{r publication_time, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
#hist(df$publication_year, main = "Document frequencies over time")
dfs <- df %>% group_by(publication_year) %>% tally()
ggplot(dfs, aes(x = publication_year, y = n)) + geom_point() + ggtitle("Document frequencies over time") + ylab("Title count") + xlab("Publication year")
```

## Publication places

Top-`r ntop` publication places are shown together with the number of documents. This info is available for `r sum(!is.na(df$publication_place))` documents (`r round(100*mean(!is.na(df$publication_place)))`%). There are `r length(unique(str_trim(unlist(strsplit(as.character(df$publication_place), ";")))))` unique publication places.

```{r publication_place, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
tab <- rev(sort(table(str_trim(unlist(strsplit(as.character(df$publication_place), ";"))))))
ntop <- 50
par(mar = c(5, 10, 3, 1)); barplot(log10(rev(tab[1:ntop])), horiz = T, las = 1, cex.names = 0.8, xlab = "Documents (log10)", main = "Most common publication places")
```

[Successfully converted publication places](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/publication_place_accepted.csv)

[Discarded publication places](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/publication_place_discarded.csv)

[Publication places missing country information](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/publication_place_missingcountry.csv)



## Dimensions

[Successfully converted dimension info](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/accepted_dimensions.csv)

[Discarded dimension info](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/missing_dimensions.csv)

[Discarded gatherings info](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/missing_gatherings.csv)


## Publisher 

[Discarded publisher info](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/publisher_discarded.csv) (Check that ok to discard these)

[Converted publishers](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/publisher_accepted.csv) (Check for formatting and synonymes)

[Self-published accepted](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/self_published_accepted.csv) (Check for formatting and synonymes)

[Self-published raw fields](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/self_published_rawfields.csv) (Check that the self-publication is a correct classification for these docs)



We also have corporate info available ?

[Accepted corporate info](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/corporate_accepted.csv)

[Discarded corporate info](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/corporate_discarded.csv)


## Authors

[Accepted unique authors](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/author_accepted.csv)

[Discarded authors](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/author_discarded.csv)

[Discarded author first names](output.tables/author_name_discarded_first.csv)

[Discarded author last names](output.tables/author_name_discarded_last.csv)

[Authors missing life years](output.tables/authors_missing_lifeyears.csv)


Top-`r ntop` uniquely identified authors and number of documents for each (duplicate docs not checked yet).

```{r authors, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
a <- rev(rev(sort(table(df$author)))[2:ntop+1])
par(mar = c(5, 10, 3, 1)); barplot(a, horiz = T, las = 1, cex.names = 0.8, xlab = "Documents", main = "Top authors")
```


## Topics

```{r topics1, topics, echo=FALSE, message=FALSE, warning=FALSE}
# List all topics
spl <- strsplit(na.omit(as.character(df$topic)), ";")

# Topics per document
# hist(sapply(spl, length))

# Documents per topic
tab <- sort(table(unlist(spl)))
tab <- tab[!names(tab) == "NA"]
tab <- rev(sort(tab)) 
```


```{r topics2, echo=FALSE, message=FALSE, warning=FALSE}
# Write to file
f <- "output.tables/subjecttopics.tab"
write.table(cbind(Topic = sort(names(tab))), file = f, sep = "\t", quote = F, row.names = F)
ntop <- 50
```

[Complete subject topic counts](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/subjecttopics.tab)

Top-`r ntop` topics and number of documents for each. In total, there are `r length(unique(df$topic))` unique topics and `r sum(!is.na(df$topic))` documents assigned to one or more topics (`r round(100*mean(!is.na(df$topic)))`).

```{r topics3, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
par(mar = c(5, 10, 3, 1)); barplot(rev(rev(sort(table(df$topic)))[1:ntop]), horiz = T, las = 1, cex.names = 0.8, xlab = "Documents", main = "Most common topics")
```


## Subject geographical places

```{r geo, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
tab <- rev(sort(table(unlist(strsplit(as.character(df$subject_geography), ";")))))
```

Top-`r ntop` geographical places are shown together with the number of documents assigned to that region. Geography information is available for `r sum(!is.na(df$subject_geography))` documents (`r round(100*mean(!is.na(df$subject_geography)))`%). There are `r length(tab)` unique geographical places.

```{r geo2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
ntop <- 50
par(mar = c(5, 10, 3, 1)); barplot(log10(rev(tab[1:ntop])), horiz = T, las = 1, cex.names = 0.8, xlab = "Documents (log10)", main = "Most common geographic places")
```

```{r geo3, echo=FALSE, message=FALSE, warning=FALSE}
f <- "output.tables/geoplaces.csv"
write.table(cbind(Geography = names(tab), Documents = tab), file = f, sep = "|", quote = F, row.names = F)
```

[Complete geoplace listing](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/geoplaces.csv)


## Geocoordinates for publication places

Altogether ```r 100 * mean(is.na(df.preprocessed$latitude) | is.na(df.preprocessed$longitude))``` places have missing geocoordinates:

[Places with missing geocoordinates](https://github.com/rOpenGov/fennica/blob/master/inst/examples/output.tables/missing_geocoordinates.csv)


